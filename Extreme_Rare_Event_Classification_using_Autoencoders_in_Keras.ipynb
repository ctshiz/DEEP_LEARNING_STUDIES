{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extreme Rare Event Classification using Autoencoders in Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqjbx/L1wafLFdCQb4+E0e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ctshiz/DEEP_LEARNING_STUDIES/blob/main/Extreme_Rare_Event_Classification_using_Autoencoders_in_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LBpZU07gGIJM"
      },
      "outputs": [],
      "source": [
        "# All credits to Chitta Ranjan\n",
        "# https://towardsdatascience.com/extreme-rare-event-classification-using-autoencoders-in-keras-a565b386f098"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the desired libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pylab import rcParams\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras import regularizers\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, recall_score, classification_report, auc, roc_curve, precision_recall_fscore_support, f1_score\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "#from tensorflow import set_random_seed\n",
        "tf.random.set_seed(2)\n",
        "\n",
        "#used to help randomly select the data points\n",
        "SEED = 123\n",
        "DATA_SPLIT_PCT = 0.2\n",
        "\n",
        "rcParams['figure.figsize'] = 8,6\n",
        "LABELS = ['Normal','Break']"
      ],
      "metadata": {
        "id": "qUo-Ay_NG1AF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read and prepare the data\n",
        "df = pd.read_csv(\"processminer-rare-event-mts - data.csv\")"
      ],
      "metadata": {
        "id": "mWKyrrpUJHVX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count number of positive labels\n",
        "pos= len(df[df['y']==1])\n",
        "neg = len(df[df['y']==0])\n",
        "tot = len(df)\n",
        "print(\"Percentual of positive labels are :\", (pos/tot)*100)\n",
        "print(\"Percentual of negative labels are :\", (neg/tot)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb_LNz9PKaWY",
        "outputId": "2d4b7feb-7991-4507-c94c-2bfc82175e63"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentual of positive labels are : 0.6739863028590064\n",
            "Percentual of negative labels are : 99.326013697141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sign = lambda x:(1,-1)[x<0]\n",
        "\n",
        "def curve_shift(df, shift_by):\n",
        "  '''\n",
        "    This function will shift the binary labels in a dataframe.\n",
        "    The curve shift will be with respect to the 1s. \n",
        "    For example, if shift is -2, the following process\n",
        "    will happen: if row n is labeled as 1, then\n",
        "    - Make row (n+shift_by):(n+shift_by-1) = 1.\n",
        "    - Remove row n.\n",
        "    i.e. the labels will be shifted up to 2 rows up.\n",
        "    \n",
        "    Inputs:\n",
        "    df       A pandas dataframe with a binary labeled column. \n",
        "             This labeled column should be named as 'y'.\n",
        "    shift_by An integer denoting the number of rows to shift.\n",
        "    \n",
        "    Output\n",
        "    df       A dataframe with the binary labels shifted by shift.\n",
        "    '''\n",
        "  vector = df['y'].copy()\n",
        "  for s in range(abs(shift_by)):\n",
        "    tmp = vector.shift(sign(shift_by))\n",
        "    tmp = tmp.fillna(0)\n",
        "    vector += tmp\n",
        "  labelcol = 'y'\n",
        "  # add vector to the df\n",
        "  df.insert(loc=0,column=labelcol+'tmp', value=vector)\n",
        "  #remove the rows ewith labelcol == 1\n",
        "  df = df.drop(df[df[labelcol]==1].index)\n",
        "  # drop labelcol and rename the tmpo col as labelcol\n",
        "  df = df.drop(labelcol, axis=1)\n",
        "  df = df.rename(columns={labelcol+'tmp':labelcol})\n",
        "  #make the labelcol binary\n",
        "  df.loc[df[labelcol] > 0, labelcol] = 1\n",
        "  return df"
      ],
      "metadata": {
        "id": "sPe59tesKbLN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove time column, and the categorial columns\n",
        "df = df.drop(['time', 'x28', 'x61'], axis=1)"
      ],
      "metadata": {
        "id": "vbxpzaBtMcAq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = train_test_split(df, test_size=DATA_SPLIT_PCT, random_state=SEED)\n",
        "df_train, df_valid = train_test_split(df_train, test_size=DATA_SPLIT_PCT, random_state=SEED)\n",
        "\n",
        "df_train_0 = df_train.loc[df['y']==0]\n",
        "df_train_1 = df_train.loc[df['y']==1]\n",
        "df_train_0_x = df_train_0.drop(['y'], axis=1)\n",
        "df_train_1_x = df_train_1.drop(['y'], axis=1)\n",
        "\n",
        "df_valid_0 = df_valid.loc[df['y']==0]\n",
        "df_valid_1 = df_valid.loc[df['y']==1]\n",
        "df_valid_0_x = df_valid_0.drop(['y'], axis=1)\n",
        "df_valid_1_x = df_valid_1.drop(['y'], axis=1)\n",
        "\n",
        "df_test_0 = df_test.loc[df['y']==0]\n",
        "df_test_1 = df_test.loc[df['y']==1]\n",
        "df_test_0_x = df_test_0.drop(['y'], axis=1)\n",
        "df_test_1_x = df_test_1.drop(['y'], axis=1)"
      ],
      "metadata": {
        "id": "7l2e99ZWTiPN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Standardization\n",
        "scaler = StandardScaler().fit(df_train_0_x)\n",
        "df_train_0_x_rescaled = scaler.transform(df_train_0_x)\n",
        "df_valid_0_x_rescaled = scaler.transform(df_valid_0_x)\n",
        "df_valid_x_rescaled = scaler.transform(df_valid.drop(['y'], axis=1))\n",
        "\n",
        "\n",
        "df_test_0_x_rescaled = scaler.transform(df_test_0_x)\n",
        "df_test_x_rescaled = scaler.transform(df_test.drop(['y'], axis=1))"
      ],
      "metadata": {
        "id": "79jhwrmwXl2V"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Autoencoder Classifier\n",
        "#initialization\n",
        "nb_epoch = 200\n",
        "batch_size = 128\n",
        "#num of predictor variables\n",
        "input_dim = df_train_0_x_rescaled.shape[1]\n",
        "encoding_dim = 32\n",
        "hidden_dim = int(encoding_dim/2)\n",
        "learning_rate = 1e-3\n",
        "\n"
      ],
      "metadata": {
        "id": "6JkeFtW1Zbrk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vOeZzPZMbhGm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}